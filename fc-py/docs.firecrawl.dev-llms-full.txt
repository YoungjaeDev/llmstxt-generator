# https://docs.firecrawl.dev/ llms-full.txt

## Firecrawl API Documentation
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Get Started

Quickstart

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

On this page

*   [Welcome to Firecrawl](https://docs.firecrawl.dev/#welcome-to-firecrawl)
    
*   [How to use it?](https://docs.firecrawl.dev/#how-to-use-it%3F)
    
*   [API Key](https://docs.firecrawl.dev/#api-key)
    
*   [Features](https://docs.firecrawl.dev/#features)
    
*   [Powerful Capabilities](https://docs.firecrawl.dev/#powerful-capabilities)
    
*   [Installing Firecrawl](https://docs.firecrawl.dev/#installing-firecrawl)
    
*   [Scraping](https://docs.firecrawl.dev/#scraping)
    
*   [Response](https://docs.firecrawl.dev/#response)
    
*   [Crawling](https://docs.firecrawl.dev/#crawling)
    
*   [Usage](https://docs.firecrawl.dev/#usage)
    
*   [Check Crawl Job](https://docs.firecrawl.dev/#check-crawl-job)
    
*   [Response](https://docs.firecrawl.dev/#response-2)
    
*   [Extraction](https://docs.firecrawl.dev/#extraction)
    
*   [Extracting without schema (New)](https://docs.firecrawl.dev/#extracting-without-schema-new)
    
*   [Interacting with the page with Actions](https://docs.firecrawl.dev/#interacting-with-the-page-with-actions)
    
*   [Example](https://docs.firecrawl.dev/#example)
    
*   [Output](https://docs.firecrawl.dev/#output)
    
*   [Open Source vs Cloud](https://docs.firecrawl.dev/#open-source-vs-cloud)
    
*   [Contributing](https://docs.firecrawl.dev/#contributing)
    

![Hero Light](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/images/turn-websites-into-llm-ready-data--firecrawl.jpg)

[‚Äã](https://docs.firecrawl.dev/#welcome-to-firecrawl)

Welcome to Firecrawl
-----------------------------------------------------------------------------

[Firecrawl](https://firecrawl.dev/?ref=github)
 is an API service that takes a URL, crawls it, and converts it into clean markdown. We crawl all accessible subpages and give you clean markdown for each. No sitemap required.

[‚Äã](https://docs.firecrawl.dev/#how-to-use-it%3F)

How to use it?
-------------------------------------------------------------------

We provide an easy to use API with our hosted version. You can find the playground and documentation [here](https://firecrawl.dev/playground)
. You can also self host the backend if you‚Äôd like. Check out the following resources to get started:

*   [x]  **API**: [Documentation](https://docs.firecrawl.dev/api-reference/introduction)
    
*   [x]  **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python)
    , [Node](https://docs.firecrawl.dev/sdks/node)
    , [Go](https://docs.firecrawl.dev/sdks/go)
    , [Rust](https://docs.firecrawl.dev/sdks/rust)
    
*   [x]  **LLM Frameworks**: [Langchain (python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/)
    , [Langchain (js)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl)
    , [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader)
    , [Crew.ai](https://docs.crewai.com/)
    , [Composio](https://composio.dev/tools/firecrawl/all)
    , [PraisonAI](https://docs.praison.ai/firecrawl/)
    , [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl)
    , [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)
    
*   [x]  **Low-code Frameworks**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl)
    , [Langflow](https://docs.langflow.org/)
    , [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl)
    , [Cargo](https://docs.getcargo.io/integration/firecrawl)
    , [Pipedream](https://pipedream.com/apps/firecrawl/)
    
*   [x]  **Others**: [Zapier](https://zapier.com/apps/firecrawl/integrations)
    , [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)
    
*   [ ]  Want an SDK or Integration? Let us know by opening an issue.

**Self-host:** To self-host refer to guide [here](https://docs.firecrawl.dev/contributing/self-host)
.

### 

[‚Äã](https://docs.firecrawl.dev/#api-key)

API Key

To use the API, you need to sign up on [Firecrawl](https://firecrawl.dev/)
 and get an API key.

### 

[‚Äã](https://docs.firecrawl.dev/#features)

Features

*   [**Scrape**](https://docs.firecrawl.dev/#scraping)
    : scrapes a URL and get its content in LLM-ready format (markdown, structured data via [LLM Extract](https://docs.firecrawl.dev/#extraction)
    , screenshot, html)
*   [**Crawl**](https://docs.firecrawl.dev/#crawling)
    : scrapes all the URLs of a web page and return content in LLM-ready format
*   [**Map**](https://docs.firecrawl.dev/features/map)
    : input a website and get all the website urls - extremely fast
*   [**Search**](https://docs.firecrawl.dev/features/search)
    : search the web and get full content from results
*   [**Extract**](https://docs.firecrawl.dev/features/extract)
    : get structured data from single page, multiple pages or entire websites with AI.

### 

[‚Äã](https://docs.firecrawl.dev/#powerful-capabilities)

Powerful Capabilities

*   **LLM-ready formats**: markdown, structured data, screenshot, HTML, links, metadata
*   **The hard stuff**: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration
*   **Customizability**: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc‚Ä¶
*   **Media parsing**: pdfs, docx, images.
*   **Reliability first**: designed to get the data you need - no matter how hard it is.
*   **Actions**: click, scroll, input, wait and more before extracting data

You can find all of Firecrawl‚Äôs capabilities and how to use them in our [documentation](https://docs.firecrawl.dev/)

[‚Äã](https://docs.firecrawl.dev/#installing-firecrawl)

Installing Firecrawl
-----------------------------------------------------------------------------

Python

Node

Go

Rust

Copy

Ask AI

    pip install firecrawl-py
    

[‚Äã](https://docs.firecrawl.dev/#scraping)

Scraping
-----------------------------------------------------

To scrape a single URL, use the `scrape_url` method. It takes the URL as a parameter and returns the scraped data as a dictionary.

Python

Node

Go

Rust

cURL

Copy

Ask AI

    from firecrawl import FirecrawlApp
    
    app = FirecrawlApp(api_key="fc-YOUR_API_KEY")
    
    # Scrape a website:
    scrape_result = app.scrape_url('firecrawl.dev', formats=['markdown', 'html'])
    print(scrape_result)
    

### 

[‚Äã](https://docs.firecrawl.dev/#response)

Response

SDKs will return the data object directly. cURL will return the payload exactly as shown below.

Copy

Ask AI

    {
      "success": true,
      "data" : {
        "markdown": "Launch Week I is here! [See our Day 2 Release üöÄ](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[üí• Get 2 months free...",\
        "html": "<!DOCTYPE html><html lang=\"en\" class=\"light\" style=\"color-scheme: light;\"><body class=\"__variable_36bd41 __variable_d7dc5d font-inter ...",\
        "metadata": {\
          "title": "Home - Firecrawl",\
          "description": "Firecrawl crawls and converts any website into clean markdown.",\
          "language": "en",\
          "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",\
          "robots": "follow, index",\
          "ogTitle": "Firecrawl",\
          "ogDescription": "Turn any website into LLM-ready data.",\
          "ogUrl": "https://www.firecrawl.dev/",\
          "ogImage": "https://www.firecrawl.dev/og.png?123",\
          "ogLocaleAlternate": [],\
          "ogSiteName": "Firecrawl",\
          "sourceURL": "https://firecrawl.dev",\
          "statusCode": 200\
        }\
      }\
    }\
    \
\
[‚Äã](https://docs.firecrawl.dev/#crawling)\
\
Crawling\
-----------------------------------------------------\
\
Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.\
\
### \
\
[‚Äã](https://docs.firecrawl.dev/#usage)\
\
Usage\
\
Python\
\
Node\
\
Go\
\
Rust\
\
cURL\
\
Copy\
\
Ask AI\
\
    from firecrawl import FirecrawlApp, ScrapeOptions\
    \
    app = FirecrawlApp(api_key="fc-YOUR_API_KEY")\
    \
    # Crawl a website:\
    crawl_result = app.crawl_url(\
      'https://firecrawl.dev', \
      limit=10, \
      scrape_options=ScrapeOptions(formats=['markdown', 'html']),\
    )\
    print(crawl_result)\
    \
\
If you‚Äôre using cURL or `async crawl` functions on SDKs, this will return an `ID` where you can use to check the status of the crawl.\
\
Copy\
\
Ask AI\
\
    {\
      "success": true,\
      "id": "123-456-789",\
      "url": "https://api.firecrawl.dev/v1/crawl/123-456-789"\
    }\
    \
\
### \
\
[‚Äã](https://docs.firecrawl.dev/#check-crawl-job)\
\
Check Crawl Job\
\
Used to check the status of a crawl job and get its result.\
\
Python\
\
Node\
\
Go\
\
Rust\
\
cURL\
\
Copy\
\
Ask AI\
\
    crawl_status = app.check_crawl_status("<crawl_id>")\
    print(crawl_status)\
    \
\
#### \
\
[‚Äã](https://docs.firecrawl.dev/#response-2)\
\
Response\
\
The response will be different depending on the status of the crawl. For not completed or large responses exceeding 10MB, a `next` URL parameter is provided. You must request this URL to retrieve the next 10MB of data. If the `next` parameter is absent, it indicates the end of the crawl data.\
\
Scraping\
\
Completed\
\
Copy\
\
Ask AI\
\
    {\
      "status": "scraping",\
      "total": 36,\
      "completed": 10,\
      "creditsUsed": 10,\
      "expiresAt": "2024-00-00T00:00:00.000Z",\
      "next": "https://api.firecrawl.dev/v1/crawl/123-456-789?skip=10",\
      "data": [\
        {\
          "markdown": "[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...",\
          "html": "<!DOCTYPE html><html lang=\"en\" class=\"js-focus-visible lg:[--scroll-mt:9.5rem]\" data-js-focus-visible=\"\">...",\
          "metadata": {\
            "title": "Build a 'Chat with website' using Groq Llama 3 | Firecrawl",\
            "language": "en",\
            "sourceURL": "https://docs.firecrawl.dev/learn/rag-llama3",\
            "description": "Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.",\
            "ogLocaleAlternate": [],\
            "statusCode": 200\
          }\
        },\
        ...\
      ]\
    }\
    \
\
[‚Äã](https://docs.firecrawl.dev/#extraction)\
\
Extraction\
---------------------------------------------------------\
\
With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it: v1 is only supported on node, python and cURL at this time.\
\
Python\
\
Node\
\
cURL\
\
Copy\
\
Ask AI\
\
    from firecrawl import JsonConfig, FirecrawlApp\
    from pydantic import BaseModel\
    app = FirecrawlApp(api_key="<YOUR_API_KEY>")\
    \
    class ExtractSchema(BaseModel):\
        company_mission: str\
        supports_sso: bool\
        is_open_source: bool\
        is_in_yc: bool\
    \
    json_config = JsonConfig(\
        schema=ExtractSchema\
    )\
    \
    llm_extraction_result = app.scrape_url(\
        'https://firecrawl.dev',\
        formats=["json"],\
        json_options=json_config,\
        only_main_content=False,\
        timeout=120000\
    )\
    \
    print(llm_extraction_result.json)\
    \
\
Output:\
\
JSON\
\
Copy\
\
Ask AI\
\
    {\
        "success": true,\
        "data": {\
          "json": {\
            "company_mission": "AI-powered web scraping and data extraction",\
            "supports_sso": true,\
            "is_open_source": true,\
            "is_in_yc": true\
          },\
          "metadata": {\
            "title": "Firecrawl",\
            "description": "AI-powered web scraping and data extraction",\
            "robots": "follow, index",\
            "ogTitle": "Firecrawl",\
            "ogDescription": "AI-powered web scraping and data extraction",\
            "ogUrl": "https://firecrawl.dev/",\
            "ogImage": "https://firecrawl.dev/og.png",\
            "ogLocaleAlternate": [],\
            "ogSiteName": "Firecrawl",\
            "sourceURL": "https://firecrawl.dev/"\
          },\
        }\
    }\
    \
\
### \
\
[‚Äã](https://docs.firecrawl.dev/#extracting-without-schema-new)\
\
Extracting without schema (New)\
\
You can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.\
\
cURL\
\
Copy\
\
Ask AI\
\
    curl -X POST https://api.firecrawl.dev/v1/scrape \\
        -H 'Content-Type: application/json' \\
        -H 'Authorization: Bearer YOUR_API_KEY' \\
        -d '{\
          "url": "https://docs.firecrawl.dev/",\
          "formats": ["json"],\
          "jsonOptions": {\
            "prompt": "Extract the company mission from the page."\
          }\
        }'\
    \
\
Output:\
\
JSON\
\
Copy\
\
Ask AI\
\
    {\
        "success": true,\
        "data": {\
          "json": {\
            "company_mission": "AI-powered web scraping and data extraction",\
          },\
          "metadata": {\
            "title": "Firecrawl",\
            "description": "AI-powered web scraping and data extraction",\
            "robots": "follow, index",\
            "ogTitle": "Firecrawl",\
            "ogDescription": "AI-powered web scraping and data extraction",\
            "ogUrl": "https://firecrawl.dev/",\
            "ogImage": "https://firecrawl.dev/og.png",\
            "ogLocaleAlternate": [],\
            "ogSiteName": "Firecrawl",\
            "sourceURL": "https://firecrawl.dev/"\
          },\
        }\
    }\
    \
\
[‚Äã](https://docs.firecrawl.dev/#interacting-with-the-page-with-actions)\
\
Interacting with the page with Actions\
-----------------------------------------------------------------------------------------------------------------\
\
Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction. Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot. It is important to almost always use the `wait` action before/after executing other actions to give enough time for the page to load.\
\
### \
\
[‚Äã](https://docs.firecrawl.dev/#example)\
\
Example\
\
Python\
\
Node\
\
cURL\
\
Copy\
\
Ask AI\
\
    from firecrawl import FirecrawlApp\
    \
    app = FirecrawlApp(api_key="fc-YOUR_API_KEY")\
    \
    # Scrape a website:\
    scrape_result = app.scrape_url('firecrawl.dev', \
        formats=['markdown', 'html'], \
        actions=[\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "click", "selector": "textarea[title=\"Search\"]"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "write", "text": "firecrawl"},\
            {"type": "wait", "milliseconds": 2000},\
            {"type": "press", "key": "ENTER"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "click", "selector": "h3"},\
            {"type": "wait", "milliseconds": 3000},\
            {"type": "scrape"},\
            {"type": "screenshot"}\
        ]\
    )\
    print(scrape_result)\
    \
\
### \
\
[‚Äã](https://docs.firecrawl.dev/#output)\
\
Output\
\
JSON\
\
Copy\
\
Ask AI\
\
    {\
      "success": true,\
      "data": {\
        "markdown": "Our first Launch Week is over! [See the recap üöÄ](blog/firecrawl-launch-week-1-recap)...",\
        "actions": {\
          "screenshots": [\
            "https://alttmdsdujxrfnakrkyi.supabase.co/storage/v1/object/public/media/screenshot-75ef2d87-31e0-4349-a478-fb432a29e241.png"\
          ],\
          "scrapes": [\
            {\
              "url": "https://www.firecrawl.dev/",\
              "html": "<html><body><h1>Firecrawl</h1></body></html>"\
            }\
          ]\
        },\
        "metadata": {\
          "title": "Home - Firecrawl",\
          "description": "Firecrawl crawls and converts any website into clean markdown.",\
          "language": "en",\
          "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",\
          "robots": "follow, index",\
          "ogTitle": "Firecrawl",\
          "ogDescription": "Turn any website into LLM-ready data.",\
          "ogUrl": "https://www.firecrawl.dev/",\
          "ogImage": "https://www.firecrawl.dev/og.png?123",\
          "ogLocaleAlternate": [],\
          "ogSiteName": "Firecrawl",\
          "sourceURL": "http://google.com",\
          "statusCode": 200\
        }\
      }\
    }\
    \
\
[‚Äã](https://docs.firecrawl.dev/#open-source-vs-cloud)\
\
Open Source vs Cloud\
-----------------------------------------------------------------------------\
\
Firecrawl is open source available under the [AGPL-3.0 license](https://github.com/mendableai/firecrawl/blob/main/LICENSE)\
. To deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users. Firecrawl Cloud is available at [firecrawl.dev](https://firecrawl.dev/)\
 and offers a range of features that are not available in the open source version: ![Firecrawl Cloud vs Open Source](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/images/open-source-cloud.png)\
\
[‚Äã](https://docs.firecrawl.dev/#contributing)\
\
Contributing\
-------------------------------------------------------------\
\
We love contributions! Please read our [contributing guide](https://github.com/mendableai/firecrawl/blob/main/CONTRIBUTING.md)\
 before submitting a pull request.\
\
[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/introduction.mdx)\
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/introduction)\
\
[MCP Server](https://docs.firecrawl.dev/mcp)\
\
Assistant\
\
Responses are generated using AI and may contain mistakes.

## Advanced Web Scraping
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Get Started

Advanced Scraping Guide

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

On this page

*   [Basic scraping with Firecrawl (/scrape)](https://docs.firecrawl.dev/advanced-scraping-guide#basic-scraping-with-firecrawl-%2Fscrape)
    
*   [Scraping PDFs](https://docs.firecrawl.dev/advanced-scraping-guide#scraping-pdfs)
    
*   [Scrape Options](https://docs.firecrawl.dev/advanced-scraping-guide#scrape-options)
    
*   [Setting the content formats on response with formats](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-content-formats-on-response-with-formats)
    
*   [Getting the full page content as markdown with onlyMainContent](https://docs.firecrawl.dev/advanced-scraping-guide#getting-the-full-page-content-as-markdown-with-onlymaincontent)
    
*   [Setting the tags to include with includeTags](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-tags-to-include-with-includetags)
    
*   [Setting the tags to exclude with excludeTags](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-tags-to-exclude-with-excludetags)
    
*   [Waiting for the page to load with waitFor](https://docs.firecrawl.dev/advanced-scraping-guide#waiting-for-the-page-to-load-with-waitfor)
    
*   [Setting the maximum timeout](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-maximum-timeout)
    
*   [Parsing PDF files with parsePDF](https://docs.firecrawl.dev/advanced-scraping-guide#parsing-pdf-files-with-parsepdf)
    
*   [Example Usage](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage)
    
*   [Extractor Options](https://docs.firecrawl.dev/advanced-scraping-guide#extractor-options)
    
*   [Using the LLM Extraction](https://docs.firecrawl.dev/advanced-scraping-guide#using-the-llm-extraction)
    
*   [schema](https://docs.firecrawl.dev/advanced-scraping-guide#schema)
    
*   [system prompt](https://docs.firecrawl.dev/advanced-scraping-guide#system-prompt)
    
*   [prompt](https://docs.firecrawl.dev/advanced-scraping-guide#prompt)
    
*   [Example Usage](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage-2)
    
*   [Actions](https://docs.firecrawl.dev/advanced-scraping-guide#actions)
    
*   [Available Actions](https://docs.firecrawl.dev/advanced-scraping-guide#available-actions)
    
*   [wait](https://docs.firecrawl.dev/advanced-scraping-guide#wait)
    
*   [screenshot](https://docs.firecrawl.dev/advanced-scraping-guide#screenshot)
    
*   [click](https://docs.firecrawl.dev/advanced-scraping-guide#click)
    
*   [write](https://docs.firecrawl.dev/advanced-scraping-guide#write)
    
*   [press](https://docs.firecrawl.dev/advanced-scraping-guide#press)
    
*   [scroll](https://docs.firecrawl.dev/advanced-scraping-guide#scroll)
    
*   [scrape](https://docs.firecrawl.dev/advanced-scraping-guide#scrape)
    
*   [pdf](https://docs.firecrawl.dev/advanced-scraping-guide#pdf)
    
*   [executeJavascript](https://docs.firecrawl.dev/advanced-scraping-guide#executejavascript)
    
*   [Crawling Multiple Pages](https://docs.firecrawl.dev/advanced-scraping-guide#crawling-multiple-pages)
    
*   [Check Crawl Job](https://docs.firecrawl.dev/advanced-scraping-guide#check-crawl-job)
    
*   [Pagination/Next URL](https://docs.firecrawl.dev/advanced-scraping-guide#pagination%2Fnext-url)
    
*   [Crawler Options](https://docs.firecrawl.dev/advanced-scraping-guide#crawler-options)
    
*   [includePaths](https://docs.firecrawl.dev/advanced-scraping-guide#includepaths)
    
*   [excludePaths](https://docs.firecrawl.dev/advanced-scraping-guide#excludepaths)
    
*   [maxDepth](https://docs.firecrawl.dev/advanced-scraping-guide#maxdepth)
    
*   [limit](https://docs.firecrawl.dev/advanced-scraping-guide#limit)
    
*   [allowBackwardLinks](https://docs.firecrawl.dev/advanced-scraping-guide#allowbackwardlinks)
    
*   [allowExternalLinks](https://docs.firecrawl.dev/advanced-scraping-guide#allowexternallinks)
    
*   [allowSubdomains](https://docs.firecrawl.dev/advanced-scraping-guide#allowsubdomains)
    
*   [delay](https://docs.firecrawl.dev/advanced-scraping-guide#delay)
    
*   [scrapeOptions](https://docs.firecrawl.dev/advanced-scraping-guide#scrapeoptions)
    
*   [Example Usage](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage-3)
    
*   [Mapping Website Links with /map](https://docs.firecrawl.dev/advanced-scraping-guide#mapping-website-links-with-%2Fmap)
    
*   [Usage](https://docs.firecrawl.dev/advanced-scraping-guide#usage)
    
*   [Example Response](https://docs.firecrawl.dev/advanced-scraping-guide#example-response)
    
*   [Map Options](https://docs.firecrawl.dev/advanced-scraping-guide#map-options)
    
*   [search](https://docs.firecrawl.dev/advanced-scraping-guide#search)
    
*   [limit](https://docs.firecrawl.dev/advanced-scraping-guide#limit-2)
    
*   [ignoreSitemap](https://docs.firecrawl.dev/advanced-scraping-guide#ignoresitemap)
    
*   [includeSubdomains](https://docs.firecrawl.dev/advanced-scraping-guide#includesubdomains)
    

This guide will walk you through the different endpoints of Firecrawl and how to use them fully with all its parameters.

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#basic-scraping-with-firecrawl-%2Fscrape)

Basic scraping with Firecrawl (/scrape)
------------------------------------------------------------------------------------------------------------------------------------------

To scrape a single page and get clean markdown content, you can use the `/scrape` endpoint.

Python

JavaScript

Go

Rust

cURL

Copy

Ask AI

    # pip install firecrawl-py
    
    from firecrawl import FirecrawlApp
    
    app = FirecrawlApp(api_key="YOUR_API_KEY")
    
    content = app.scrape_url("https://docs.firecrawl.dev")
    

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#scraping-pdfs)

Scraping PDFs
--------------------------------------------------------------------------------------

**Firecrawl supports scraping PDFs by default.** You can use the `/scrape` endpoint to scrape a PDF link and get the text content of the PDF. You can disable this by setting `parsePDF` to `false`.

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#scrape-options)

Scrape Options
----------------------------------------------------------------------------------------

When using the `/scrape` endpoint, you can customize the scraping behavior with many parameters. Here are the available options:

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-content-formats-on-response-with-formats)

Setting the content formats on response with `formats`

*   **Type**: `array`
*   **Enum**: `["markdown", "links", "html", "rawHtml", "screenshot", "json"]`
*   **Description**: Specify the formats to include in the response. Options include:
    *   `markdown`: Returns the scraped content in Markdown format.
    *   `links`: Includes all hyperlinks found on the page.
    *   `html`: Provides the content in HTML format.
    *   `rawHtml`: Delivers the raw HTML content, without any processing.
    *   `screenshot`: Includes a screenshot of the page as it appears in the browser.
    *   `json`: Extracts structured information from the page using the LLM.
*   **Default**: `["markdown"]`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#getting-the-full-page-content-as-markdown-with-onlymaincontent)

Getting the full page content as markdown with `onlyMainContent`

*   **Type**: `boolean`
*   **Description**: By default, the scraper will only return the main content of the page, excluding headers, navigation bars, footers, etc. Set this to `false` to return the full page content.
*   **Default**: `true`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-tags-to-include-with-includetags)

Setting the tags to include with `includeTags`

*   **Type**: `array`
*   **Description**: Specify the HTML tags, classes and ids to include in the response.
*   **Default**: undefined

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-tags-to-exclude-with-excludetags)

Setting the tags to exclude with `excludeTags`

*   **Type**: `array`
*   **Description**: Specify the HTML tags, classes and ids to exclude from the response.
*   **Default**: undefined

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#waiting-for-the-page-to-load-with-waitfor)

Waiting for the page to load with `waitFor`

*   **Type**: `integer`
*   **Description**: To be used only as a last resort. Wait for a specified amount of milliseconds for the page to load before fetching content.
*   **Default**: `0`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-maximum-timeout)

Setting the maximum `timeout`

*   **Type**: `integer`
*   **Description**: Set the maximum duration in milliseconds that the scraper will wait for the page to respond before aborting the operation.
*   **Default**: `30000` (30 seconds)

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#parsing-pdf-files-with-parsepdf)

Parsing PDF files with `parsePDF`

*   **Type**: `boolean`
*   **Description**: Controls how PDF files are processed during scraping. When `true`, the PDF content is extracted and converted to markdown format, with billing based on the number of pages (1 credit per page). When `false`, the PDF file is returned in base64 encoding with a flat rate of 1 credit total.
*   **Default**: `true`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage)

Example Usage

Copy

Ask AI

    curl -X POST https://api.firecrawl.dev/v1/scrape \
        -H '
        Content-Type: application/json' \
        -H 'Authorization : Bearer YOUR_API_KEY' \
        -d '{
          "url": "https://docs.firecrawl.dev",
          "formats": ["markdown", "links", "html", "rawHtml", "screenshot"],
          "includeTags": ["h1", "p", "a", ".main-content"],
          "excludeTags": ["#ad", "#footer"],
          "onlyMainContent": false,
          "waitFor": 1000,
          "timeout": 15000,
          "parsePDF": false
        }'
    

In this example, the scraper will:

*   Return the full page content as markdown.
*   Include the markdown, raw HTML, HTML, links and screenshot in the response.
*   The response will include only the HTML tags `<h1>`, `<p>`, `<a>`, and elements with the class `.main-content`, while excluding any elements with the IDs `#ad` and `#footer`.
*   Wait for 1000 milliseconds (1 second) for the page to load before fetching the content.
*   Set the maximum duration of the scrape request to 15000 milliseconds (15 seconds).
*   Return PDF files in base64 format instead of converting them to markdown.

Here is the API Reference for it: [Scrape Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#extractor-options)

Extractor Options
----------------------------------------------------------------------------------------------

When using the `/scrape` endpoint, you can specify options for **extracting structured information** from the page content using the `extract` parameter. Here are the available options:

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#using-the-llm-extraction)

Using the LLM Extraction

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#schema)

schema

*   **Type**: `object`
*   **Required**: False if prompt is provided
*   **Description**: The schema for the data to be extracted. This defines the structure of the extracted data.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#system-prompt)

system prompt

*   **Type**: `string`
*   **Required**: False
*   **Description**: System prompt for the LLM.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#prompt)

prompt

*   **Type**: `string`
*   **Required**: False if schema is provided
*   **Description**: A prompt for the LLM to extract the data in the correct structure.
*   **Example**: `"Extract the features of the product"`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage-2)

Example Usage

Copy

Ask AI

    curl -X POST https://api.firecrawl.dev/v0/scrape \
        -H 'Content-Type: application/json' \
        -H 'Authorization: Bearer YOUR_API_KEY' \
        -d '{
          "url": "https://firecrawl.dev",
          "formats": ["markdown", "json"],
          "json": {
            "prompt": "Extract the features of the product"
          }
        }'
    

Copy

Ask AI

    {
      "success": true,
      "data": {
        "content": "Raw Content",
        "metadata": {
          "title": "Mendable",
          "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
          "robots": "follow, index",
          "ogTitle": "Mendable",
          "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
          "ogUrl": "https://docs.firecrawl.dev/",
          "ogImage": "https://docs.firecrawl.dev/mendable_new_og1.png",
          "ogLocaleAlternate": [],
          "ogSiteName": "Mendable",
          "sourceURL": "https://docs.firecrawl.dev/",
          "statusCode": 200
        },
        "extract": {
          "product": "Firecrawl",
          "features": {
            "general": {
              "description": "Turn websites into LLM-ready data.",
              "openSource": true,
              "freeCredits": 500,
              "useCases": [\
                "AI applications",\
                "Data science",\
                "Market research",\
                "Content aggregation"\
              ]
            },
            "crawlingAndScraping": {
              "crawlAllAccessiblePages": true,
              "noSitemapRequired": true,
              "dynamicContentHandling": true,
              "dataCleanliness": {
                "process": "Advanced algorithms",
                "outputFormat": "Markdown"
              }
            },
            ...
          }
        }
      }
    }
    

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#actions)

Actions
--------------------------------------------------------------------------

When using the `/scrape` endpoint, Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#available-actions)

Available Actions

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#wait)

wait

*   **Type**: `object`
*   **Description**: Wait for a specified amount of milliseconds.
*   **Properties**:
    *   `type`: `"wait"`
    *   `milliseconds`: Number of milliseconds to wait.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "wait",
          "milliseconds": 2000
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#screenshot)

screenshot

*   **Type**: `object`
*   **Description**: Take a screenshot.
*   **Properties**:
    *   `type`: `"screenshot"`
    *   `fullPage`: Should the screenshot be full-page or viewport sized? (default: `false`)
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "screenshot",
          "fullPage": true
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#click)

click

*   **Type**: `object`
*   **Description**: Click on an element.
*   **Properties**:
    *   `type`: `"click"`
    *   `selector`: Query selector to find the element by.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "click",
          "selector": "#load-more-button"
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#write)

write

*   **Type**: `object`
*   **Description**: Write text into an input field.
*   **Properties**:
    *   `type`: `"write"`
    *   `text`: Text to type.
    *   `selector`: Query selector for the input field.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "write",
          "text": "Hello, world!",
          "selector": "#search-input"
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#press)

press

*   **Type**: `object`
*   **Description**: Press a key on the page.
*   **Properties**:
    *   `type`: `"press"`
    *   `key`: Key to press.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "press",
          "key": "Enter"
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#scroll)

scroll

*   **Type**: `object`
*   **Description**: Scroll the page.
*   **Properties**:
    *   `type`: `"scroll"`
    *   `direction`: Direction to scroll (`"up"` or `"down"`).
    *   `amount`: Amount to scroll in pixels.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "scroll",
          "direction": "down",
          "amount": 500
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#scrape)

scrape

*   **Type**: `object`
*   **Description**: Scrape the current page content, returns the url and the html. The scraped content will be returned in the `actions.scrapes` array of the response.
*   **Properties**:
    *   `type`: `"scrape"`
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "scrape"
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#pdf)

pdf

*   **Type**: `object`
*   **Description**: Generate a PDF of the current page. The PDF will be returned in the `actions.pdfs` array of the response.
*   **Properties**:
    *   `type`: `"pdf"`
    *   `format`: The page size of the resulting PDF (default: `"Letter"`)
    *   `landscape`: Whether to generate the PDF in landscape orientation (default: `false`)
    *   `scale`: The scale multiplier of the resulting PDF (default: `1`)
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "pdf",
          "format": "A4",
          "landscape": true,
          "scale": 0.8
        }
        
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#executejavascript)

executeJavascript

*   **Type**: `object`
*   **Description**: Execute JavaScript code on the page. The return values will be returned in the `actions.javascriptReturns` array of the response.
*   **Properties**:
    *   `type`: `"executeJavascript"`
    *   `script`: JavaScript code to execute.
*   **Example**:
    
    Copy
    
    Ask AI
    
        {
          "type": "executeJavascript",
          "script": "document.querySelector('.button').click();"
        }
        
    

For more details about the actions parameters, refer to the [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape)
.

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#crawling-multiple-pages)

Crawling Multiple Pages
----------------------------------------------------------------------------------------------------------

To crawl multiple pages, you can use the `/crawl` endpoint. This endpoint allows you to specify a base URL you want to crawl and all accessible subpages will be crawled.

Copy

Ask AI

    curl -X POST https://api.firecrawl.dev/v1/crawl \
        -H 'Content-Type: application/json' \
        -H 'Authorization: Bearer YOUR_API_KEY' \
        -d '{
          "url": "https://docs.firecrawl.dev"
        }'
    

Returns an id

Copy

Ask AI

    { "id": "1234-5678-9101" }
    

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#check-crawl-job)

Check Crawl Job

Used to check the status of a crawl job and get its result.

Copy

Ask AI

    curl -X GET https://api.firecrawl.dev/v1/crawl/1234-5678-9101 \
      -H 'Content-Type: application/json' \
      -H 'Authorization: Bearer YOUR_API_KEY'
    

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#pagination%2Fnext-url)

Pagination/Next URL

If the content is larger than 10MB or if the crawl job is still running, the response will include a `next` parameter. This parameter is a URL to the next page of results. You can use this parameter to get the next page of results.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#crawler-options)

Crawler Options

When using the `/crawl` endpoint, you can customize the crawling behavior with request body parameters. Here are the available options:

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#includepaths)

`includePaths`

*   **Type**: `array`
*   **Description**: Regex patterns to include in the crawl. Only URLs matching these patterns will be crawled. For example, `^/blog/.*` will match any URL that starts with `/blog/`.
*   **Example**: `["^/blog/.*$", "^/docs/.*$"]`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#excludepaths)

`excludePaths`

*   **Type**: `array`
*   **Description**: Regex patterns to exclude from the crawl. URLs matching these patterns will be skipped. For example, `^/admin/.*` will exclude any URL that starts with `/admin/`.
*   **Example**: `["^/admin/.*$", "^/private/.*$"]`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#maxdepth)

`maxDepth`

*   **Type**: `integer`
*   **Description**: Maximum absolute depth to crawl from the base of the entered URL. For example, if the entered URL‚Äôs path is `/features/feature-1`, then no results would be returned unless `maxDepth` is at least 2.
*   **Example**: `2`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#limit)

`limit`

*   **Type**: `integer`
*   **Description**: Maximum number of pages to crawl.
*   **Default**: `10000`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#allowbackwardlinks)

`allowBackwardLinks`

*   **Type**: `boolean`
*   **Description**: Allows the crawler to follow internal links to sibling or parent URLs, not just child paths.
    *   **false**: Only crawls deeper (child) URLs.
        *   e.g. /features/feature-1 ‚Üí /features/feature-1/tips ‚úÖ
        *   Won‚Äôt follow /pricing or / ‚ùå
    *   **true**: Crawls any internal links, including siblings and parents.
        *   e.g. /features/feature-1 ‚Üí /pricing, /, etc. ‚úÖ
    *   Use true for broader internal coverage beyond nested paths.
*   **Default**: `false`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#allowexternallinks)

`allowExternalLinks`

*   **Type**: `boolean`
*   **Description**: This option allows the crawler to follow links that point to external domains. Be careful with this option, as it can cause the crawl to stop only based only on the`limit` and `maxDepth` values.
*   **Default**: `false`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#allowsubdomains)

`allowSubdomains`

*   **Type**: `boolean`
*   **Description**: Allows the crawler to follow links to subdomains of the main domain. For example, if crawling `example.com`, this would allow following links to `blog.example.com` or `api.example.com`.
*   **Default**: `false`

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#delay)

`delay`

*   **Type**: `number`
*   **Description**: Delay in seconds between scrapes. This helps respect website rate limits and prevent overwhelming the target website. If not provided, the crawler may use the robots.txt crawl delay if available.
*   **Default**: `undefined`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#scrapeoptions)

scrapeOptions

As part of the crawler options, you can also specify the `scrapeOptions` parameter. This parameter allows you to customize the scraping behavior for each page.

*   **Type**: `object`
*   **Description**: Options for the scraper.
*   **Example**: `{"formats": ["markdown", "links", "html", "rawHtml", "screenshot"], "includeTags": ["h1", "p", "a", ".main-content"], "excludeTags": ["#ad", "#footer"], "onlyMainContent": false, "waitFor": 1000, "timeout": 15000}`
*   **Default**: `{ "formats": ["markdown"] }`
*   **See**: [Scrape Options](https://docs.firecrawl.dev/advanced-scraping-guide#setting-the-content-formats-on-response-with-formats)
    

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#example-usage-3)

Example Usage

Copy

Ask AI

    curl -X POST https://api.firecrawl.dev/v1/crawl \
        -H 'Content-Type: application/json' \
        -H 'Authorization : Bearer YOUR_API_KEY' \
        -d '{
          "url": "https://docs.firecrawl.dev",
          "includePaths": ["^/blog/.*$", "^/docs/.*$"],
          "excludePaths": ["^/admin/.*$", "^/private/.*$"],
          "maxDepth": 2,
          "limit": 1000
        }'
    

In this example, the crawler will:

*   Only crawl URLs that match the patterns `^/blog/.*$` and `^/docs/.*$`.
*   Skip URLs that match the patterns `^/admin/.*$` and `^/private/.*$`.
*   Return the full document data for each page.
*   Crawl up to a maximum depth of 2.
*   Crawl a maximum of 1000 pages.

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#mapping-website-links-with-%2Fmap)

Mapping Website Links with `/map`
------------------------------------------------------------------------------------------------------------------------------

The `/map` endpoint is adept at identifying URLs that are contextually related to a given website. This feature is crucial for understanding a site‚Äôs contextual link environment, which can greatly aid in strategic site analysis and navigation planning.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#usage)

Usage

To use the `/map` endpoint, you need to send a GET request with the URL of the page you want to map. Here is an example using `curl`:

Copy

Ask AI

    curl -X POST https://api.firecrawl.dev/v1/map \
        -H 'Content-Type: application/json' \
        -H 'Authorization: Bearer YOUR_API_KEY' \
        -d '{
          "url": "https://docs.firecrawl.dev"
        }'
    

This will return a JSON object containing links contextually related to the url.

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#example-response)

Example Response

Copy

Ask AI

      {
        "success":true,
        "links":[\
          "https://docs.firecrawl.dev",\
          "https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete",\
          "https://docs.firecrawl.dev/api-reference/endpoint/crawl-get",\
          "https://docs.firecrawl.dev/api-reference/endpoint/crawl-post",\
          "https://docs.firecrawl.dev/api-reference/endpoint/map",\
          "https://docs.firecrawl.dev/api-reference/endpoint/scrape",\
          "https://docs.firecrawl.dev/api-reference/introduction",\
          "https://docs.firecrawl.dev/articles/search-announcement",\
          ...\
        ]
      }
    

### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#map-options)

Map Options

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#search)

`search`

*   **Type**: `string`
*   **Description**: Search for links containing specific text.
*   **Example**: `"blog"`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#limit-2)

`limit`

*   **Type**: `integer`
*   **Description**: Maximum number of links to return.
*   **Default**: `100`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#ignoresitemap)

`ignoreSitemap`

*   **Type**: `boolean`
*   **Description**: Ignore the website sitemap when crawling
*   **Default**: `true`

#### 

[‚Äã](https://docs.firecrawl.dev/advanced-scraping-guide#includesubdomains)

`includeSubdomains`

*   **Type**: `boolean`
*   **Description**: Include subdomains of the website
*   **Default**: `true`

Here is the API Reference for it: [Map Endpoint Documentation](https://docs.firecrawl.dev/api-reference/endpoint/map)
 Thanks for reading!

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/advanced-scraping-guide.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/advanced-scraping-guide)

[Rate Limits](https://docs.firecrawl.dev/rate-limits)
[Scrape](https://docs.firecrawl.dev/features/scrape)

Assistant

Responses are generated using AI and may contain mistakes.

## FIRE-1 Agent Guide
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Agentic Features

FIRE-1 Agent (Beta)

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

On this page

*   [What FIRE-1 Can Do:](https://docs.firecrawl.dev/agents/fire-1#what-fire-1-can-do%3A)
    
*   [How to Enable FIRE-1](https://docs.firecrawl.dev/agents/fire-1#how-to-enable-fire-1)
    
*   [Example Usage with Scrape Endpoint](https://docs.firecrawl.dev/agents/fire-1#example-usage-with-scrape-endpoint)
    
*   [Using FIRE-1 with the Extract Endpoint](https://docs.firecrawl.dev/agents/fire-1#using-fire-1-with-the-extract-endpoint)
    
*   [Billing](https://docs.firecrawl.dev/agents/fire-1#billing)
    
*   [Rate limits](https://docs.firecrawl.dev/agents/fire-1#rate-limits)
    

FIRE-1 is an AI agent that enhances Firecrawl‚Äôs scraping capabilities. It can controls browser actions and navigates complex website structures to enable comprehensive data extraction beyond traditional scraping methods.

### 

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#what-fire-1-can-do%3A)

What FIRE-1 Can Do:

*   Plan and take actions to uncover data
*   Interact with buttons, links, inputs, and dynamic elements.
*   Get mulitple pages of data that require pagination, multiple steps, etc.

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#how-to-enable-fire-1)

How to Enable FIRE-1
------------------------------------------------------------------------------------------

Activating FIRE-1 is straightforward. Simply include an `agent` object in your scrape API request:

Copy

Ask AI

    "agent": {
      "model": "FIRE-1",
      "prompt": "Your detailed navigation instructions here."
    }
    

_Note:_ The `prompt` field is required for scrape requests, instructing FIRE-1 precisely how to interact with the webpage. For `/extract` it will use the prompt provided in the `prompt` parameter on the body of the request so you can omit the above `agent.prompt` field.

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#example-usage-with-scrape-endpoint)

Example Usage with Scrape Endpoint
----------------------------------------------------------------------------------------------------------------------

Here‚Äôs a quick example using FIRE-1 with the scrape endpoint to get the companies on the consumer space from Y Combinator:

Python

Node

curl

Copy

Ask AI

    from firecrawl import FirecrawlApp
    
    app = FirecrawlApp(api_key="fc-YOUR_API_KEY")
    
    # Scrape a website:
    scrape_result = app.scrape_url('firecrawl.dev',
      formats=['markdown', 'html'],
      agent={
        'model': 'FIRE-1',
        'prompt': 'Navigate through the product listings by clicking the \'Next Page\' button until disabled. Scrape each page.'
      }
    )
    
    print(scrape_result)
    

In this scenario, FIRE-1 intelligently clicks the W22 button, the Consumer space button and scrapes the companies.

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#using-fire-1-with-the-extract-endpoint)

Using FIRE-1 with the Extract Endpoint
------------------------------------------------------------------------------------------------------------------------------

Similarly, you can leverage the FIRE-1 agent with the `/v1/extract` endpoint for complex extraction tasks that require navigation across multiple pages or interaction with elements. **Example:**

Python

Node

curl

Copy

Ask AI

    from firecrawl import FirecrawlApp
    
    app = FirecrawlApp(api_key="fc-YOUR_API_KEY")
    
    # Extract data from a website:
    extract_result = app.extract(['firecrawl.dev'],
      prompt="Extract all user comments from this forum thread.",
      schema={
        "type": "object",
        "properties": {
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "author": {"type": "string"},
                "comment_text": {"type": "string"}
              },
              "required": ["author", "comment_text"]
            }
          }
        },
        "required": ["comments"]
      },
      agent={
        "model": "FIRE-1"
      }
    )
    
    print(extract_result)
    

> FIRE-1 is already live and available under preview.

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#billing)

Billing
----------------------------------------------------------------

| Endpoint | Base Cost | Agent Cost (Preview) | Notes |
| --- | --- | --- | --- |
| `/scrape` | 150 credits per page | 0‚Äì900 agent credits per page | Varies by task complexity. |
| `/extract` | See token calculator | ~8x non-agent extract | Uses token-based pricing. |

*   **Why is FIRE-1 more expensive?**  
    FIRE-1 leverages advanced browser automation and AI planning to interact with complex web pages, which requires more compute resources than standard extraction.

> **Note:** FIRE-1 is currently in preview. Pricing and limits may change. For the latest details on `/extract` costs, see our [token calculator](https://www.firecrawl.dev/pricing?extract-pricing=true#token-calculator)
> .

[‚Äã](https://docs.firecrawl.dev/agents/fire-1#rate-limits)

Rate limits
------------------------------------------------------------------------

*   `/scrape`: 10 requests per minute
*   `/extract`: 10 requests per minute

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/agents/fire-1.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/agents/fire-1)

[Extract](https://docs.firecrawl.dev/features/extract)
[Open Source vs Cloud](https://docs.firecrawl.dev/contributing/open-source-or-cloud)

Assistant

Responses are generated using AI and may contain mistakes.

## Batch Scrape API
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Scrape Endpoints

Batch Scrape

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Scrape multiple URLs and optionally extract information using an LLM

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/batch/scrape \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "urls": [\
        "<string>"\
      ],
      "webhook": {
        "url": "<string>",
        "headers": {},
        "metadata": {},
        "events": [\
          "completed"\
        ]
      },
      "maxConcurrency": 123,
      "ignoreInvalidURLs": false,
      "onlyMainContent": true,
      "includeTags": [\
        "<string>"\
      ],
      "excludeTags": [\
        "<string>"\
      ],
      "maxAge": 0,
      "headers": {},
      "waitFor": 0,
      "mobile": false,
      "skipTlsVerification": false,
      "timeout": 30000,
      "parsePDF": true,
      "jsonOptions": {
        "schema": {},
        "systemPrompt": "<string>",
        "prompt": "<string>"
      },
      "actions": [\
        {\
          "type": "wait",\
          "milliseconds": 2,\
          "selector": "#my-element"\
        }\
      ],
      "location": {
        "country": "US",
        "languages": [\
          "en-US"\
        ]
      },
      "removeBase64Images": true,
      "blockAds": true,
      "proxy": "basic",
      "storeInCache": true,
      "formats": [\
        "markdown"\
      ],
      "changeTrackingOptions": {
        "modes": [\
          "git-diff"\
        ],
        "schema": {},
        "prompt": "<string>",
        "tag": null
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "url": "<string>",
      "invalidURLs": [\
        "<string>"\
      ]
    }

POST

/

batch

/

scrape

Try it

Scrape multiple URLs and optionally extract information using an LLM

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/batch/scrape \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "urls": [\
        "<string>"\
      ],
      "webhook": {
        "url": "<string>",
        "headers": {},
        "metadata": {},
        "events": [\
          "completed"\
        ]
      },
      "maxConcurrency": 123,
      "ignoreInvalidURLs": false,
      "onlyMainContent": true,
      "includeTags": [\
        "<string>"\
      ],
      "excludeTags": [\
        "<string>"\
      ],
      "maxAge": 0,
      "headers": {},
      "waitFor": 0,
      "mobile": false,
      "skipTlsVerification": false,
      "timeout": 30000,
      "parsePDF": true,
      "jsonOptions": {
        "schema": {},
        "systemPrompt": "<string>",
        "prompt": "<string>"
      },
      "actions": [\
        {\
          "type": "wait",\
          "milliseconds": 2,\
          "selector": "#my-element"\
        }\
      ],
      "location": {
        "country": "US",
        "languages": [\
          "en-US"\
        ]
      },
      "removeBase64Images": true,
      "blockAds": true,
      "proxy": "basic",
      "storeInCache": true,
      "formats": [\
        "markdown"\
      ],
      "changeTrackingOptions": {
        "modes": [\
          "git-diff"\
        ],
        "schema": {},
        "prompt": "<string>",
        "tag": null
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "url": "<string>",
      "invalidURLs": [\
        "<string>"\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/batch-scrape.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape)

[Scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)
[Get Batch Scrape Status](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get)

Assistant

Responses are generated using AI and may contain mistakes.

## Cancel Batch Scrape
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Scrape Endpoints

Cancel Batch Scrape

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Cancel a batch scrape job

cURL

Copy

Ask AI

    curl --request DELETE \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id} \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "message": "Batch scrape job successfully cancelled."
    }

DELETE

/

batch

/

scrape

/

{id}

Try it

Cancel a batch scrape job

cURL

Copy

Ask AI

    curl --request DELETE \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id} \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "message": "Batch scrape job successfully cancelled."
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-delete#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-delete#parameter-id)

id

string<uuid>

required

The ID of the batch scrape job

#### Response

200

200404500

application/json

Successful cancellation

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/batch-scrape-delete.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape-delete)

[Get Batch Scrape Status](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get)
[Get Batch Scrape Errors](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors)

Assistant

Responses are generated using AI and may contain mistakes.

## Batch Scrape Status
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

Ctrl KAsk AI

Search...

Navigation

Scrape Endpoints

Get Batch Scrape Status

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get the status of a batch scrape job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id} \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "status": "<string>",
      "total": 123,
      "completed": 123,
      "creditsUsed": 123,
      "expiresAt": "2023-11-07T05:31:56Z",
      "next": "<string>",
      "data": [\
        {\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "language": "<string>",\
            "sourceURL": "<string>",\
            "<any other metadata> ": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ]
    }

GET

/

batch

/

scrape

/

{id}

Try it

Get the status of a batch scrape job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id} \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "status": "<string>",
      "total": 123,
      "completed": 123,
      "creditsUsed": 123,
      "expiresAt": "2023-11-07T05:31:56Z",
      "next": "<string>",
      "data": [\
        {\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "language": "<string>",\
            "sourceURL": "<string>",\
            "<any other metadata> ": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#parameter-id)

id

string<uuid>

required

The ID of the batch scrape job

#### Response

200

200402429500

application/json

Successful response

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-status)

status

string

The current status of the batch scrape. Can be `scraping`, `completed`, or `failed`.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-total)

total

integer

The total number of pages that were attempted to be scraped.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-completed)

completed

integer

The number of pages that have been successfully scraped.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-credits-used)

creditsUsed

integer

The number of credits used for the batch scrape.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-expires-at)

expiresAt

string<date-time>

The date and time when the batch scrape will expire.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-next)

next

string | null

The URL to retrieve the next 10MB of data. Returned if the batch scrape is not completed or if the response is larger than 10MB.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get#response-data)

data

object\[\]

The data of the batch scrape.

Show child attributes

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/batch-scrape-get.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape-get)

[Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape)
[Cancel Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-delete)

Assistant

Responses are generated using AI and may contain mistakes.

## Batch Scrape Errors
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Scrape Endpoints

Get Batch Scrape Errors

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get the errors of a batch scrape job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id}/errors \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "errors": [\
        {\
          "id": "<string>",\
          "timestamp": "<string>",\
          "url": "<string>",\
          "error": "<string>"\
        }\
      ],
      "robotsBlocked": [\
        "<string>"\
      ]
    }

GET

/

batch

/

scrape

/

{id}

/

errors

Try it

Get the errors of a batch scrape job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/batch/scrape/{id}/errors \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "errors": [\
        {\
          "id": "<string>",\
          "timestamp": "<string>",\
          "url": "<string>",\
          "error": "<string>"\
        }\
      ],
      "robotsBlocked": [\
        "<string>"\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors#parameter-id)

id

string<uuid>

required

The ID of the batch scrape job

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/batch-scrape-get-errors.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/batch-scrape-get-errors)

[Cancel Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-delete)
[Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post)

Assistant

Responses are generated using AI and may contain mistakes.

## Get Active Crawls
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Crawl Endpoints

Get Active Crawls

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get all active crawls for the authenticated team

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/active \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "crawls": [\
        {\
          "id": "3c90c3cc-0d44-4b50-8888-8dd25736052a",\
          "teamId": "<string>",\
          "url": "<string>",\
          "options": {\
            "scrapeOptions": {\
              "onlyMainContent": true,\
              "includeTags": [\
                "<string>"\
              ],\
              "excludeTags": [\
                "<string>"\
              ],\
              "maxAge": 0,\
              "headers": {},\
              "waitFor": 0,\
              "mobile": false,\
              "skipTlsVerification": false,\
              "timeout": 30000,\
              "parsePDF": true,\
              "jsonOptions": {\
                "schema": {},\
                "systemPrompt": "<string>",\
                "prompt": "<string>"\
              },\
              "actions": [\
                {\
                  "type": "wait",\
                  "milliseconds": 2,\
                  "selector": "#my-element"\
                }\
              ],\
              "location": {\
                "country": "US",\
                "languages": [\
                  "en-US"\
                ]\
              },\
              "removeBase64Images": true,\
              "blockAds": true,\
              "proxy": "basic",\
              "storeInCache": true,\
              "formats": [\
                "markdown"\
              ],\
              "changeTrackingOptions": {\
                "modes": [\
                  "git-diff"\
                ],\
                "schema": {},\
                "prompt": "<string>",\
                "tag": null\
              }\
            }\
          }\
        }\
      ]
    }

GET

/

crawl

/

active

Try it

Get all active crawls for the authenticated team

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/active \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "crawls": [\
        {\
          "id": "3c90c3cc-0d44-4b50-8888-8dd25736052a",\
          "teamId": "<string>",\
          "url": "<string>",\
          "options": {\
            "scrapeOptions": {\
              "onlyMainContent": true,\
              "includeTags": [\
                "<string>"\
              ],\
              "excludeTags": [\
                "<string>"\
              ],\
              "maxAge": 0,\
              "headers": {},\
              "waitFor": 0,\
              "mobile": false,\
              "skipTlsVerification": false,\
              "timeout": 30000,\
              "parsePDF": true,\
              "jsonOptions": {\
                "schema": {},\
                "systemPrompt": "<string>",\
                "prompt": "<string>"\
              },\
              "actions": [\
                {\
                  "type": "wait",\
                  "milliseconds": 2,\
                  "selector": "#my-element"\
                }\
              ],\
              "location": {\
                "country": "US",\
                "languages": [\
                  "en-US"\
                ]\
              },\
              "removeBase64Images": true,\
              "blockAds": true,\
              "proxy": "basic",\
              "storeInCache": true,\
              "formats": [\
                "markdown"\
              ],\
              "changeTrackingOptions": {\
                "modes": [\
                  "git-diff"\
                ],\
                "schema": {},\
                "prompt": "<string>",\
                "tag": null\
              }\
            }\
          }\
        }\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-active#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/crawl-active.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-active)

[Get Crawl Errors](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors)
[Map](https://docs.firecrawl.dev/api-reference/endpoint/map)

Assistant

Responses are generated using AI and may contain mistakes.

## Cancel Crawl Job
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Crawl Endpoints

Cancel Crawl

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Cancel a crawl job

cURL

Copy

Ask AI

    curl --request DELETE \
      --url https://api.firecrawl.dev/v1/crawl/{id} \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "status": "cancelled"
    }

DELETE

/

crawl

/

{id}

Try it

Cancel a crawl job

cURL

Copy

Ask AI

    curl --request DELETE \
      --url https://api.firecrawl.dev/v1/crawl/{id} \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "status": "cancelled"
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete#parameter-id)

id

string<uuid>

required

The ID of the crawl job

#### Response

200

200404500

application/json

Successful cancellation

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/crawl-delete.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-delete)

[Get Crawl Status](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get)
[Get Crawl Errors](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors)

Assistant

Responses are generated using AI and may contain mistakes.

## Get Crawl Status
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Crawl Endpoints

Get Crawl Status

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get the status of a crawl job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/{id} \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "status": "<string>",
      "total": 123,
      "completed": 123,
      "creditsUsed": 123,
      "expiresAt": "2023-11-07T05:31:56Z",
      "next": "<string>",
      "data": [\
        {\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "language": "<string>",\
            "sourceURL": "<string>",\
            "<any other metadata> ": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ]
    }

GET

/

crawl

/

{id}

Try it

Get the status of a crawl job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/{id} \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "status": "<string>",
      "total": 123,
      "completed": 123,
      "creditsUsed": 123,
      "expiresAt": "2023-11-07T05:31:56Z",
      "next": "<string>",
      "data": [\
        {\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "language": "<string>",\
            "sourceURL": "<string>",\
            "<any other metadata> ": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get#parameter-id)

id

string<uuid>

required

The ID of the crawl job

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/crawl-get.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-get)

[Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post)
[Cancel Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete)

Assistant

Responses are generated using AI and may contain mistakes.

## Get Crawl Errors
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Crawl Endpoints

Get Crawl Errors

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get the errors of a crawl job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/{id}/errors \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "errors": [\
        {\
          "id": "<string>",\
          "timestamp": "<string>",\
          "url": "<string>",\
          "error": "<string>"\
        }\
      ],
      "robotsBlocked": [\
        "<string>"\
      ]
    }

GET

/

crawl

/

{id}

/

errors

Try it

Get the errors of a crawl job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/crawl/{id}/errors \
      --header 'Authorization: Bearer <token>'

200

402

429

500

Copy

Ask AI

    {
      "errors": [\
        {\
          "id": "<string>",\
          "timestamp": "<string>",\
          "url": "<string>",\
          "error": "<string>"\
        }\
      ],
      "robotsBlocked": [\
        "<string>"\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get-errors#parameter-id)

id

string<uuid>

required

The ID of the crawl job

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/crawl-get-errors.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-get-errors)

[Cancel Crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl-delete)
[Get Active Crawls](https://docs.firecrawl.dev/api-reference/endpoint/crawl-active)

Assistant

Responses are generated using AI and may contain mistakes.

## Crawl API Endpoint
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Crawl Endpoints

Crawl

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Crawl multiple URLs based on options

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/crawl \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "excludePaths": [\
        "<string>"\
      ],
      "includePaths": [\
        "<string>"\
      ],
      "maxDepth": 10,
      "maxDiscoveryDepth": 123,
      "ignoreSitemap": false,
      "ignoreQueryParameters": false,
      "limit": 10000,
      "allowBackwardLinks": false,
      "crawlEntireDomain": false,
      "allowExternalLinks": false,
      "allowSubdomains": false,
      "delay": 123,
      "maxConcurrency": 123,
      "webhook": {
        "url": "<string>",
        "headers": {},
        "metadata": {},
        "events": [\
          "completed"\
        ]
      },
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": [\
          "markdown"\
        ],
        "changeTrackingOptions": {
          "modes": [\
            "git-diff"\
          ],
          "schema": {},
          "prompt": "<string>",
          "tag": null
        }
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "url": "<string>"
    }

POST

/

crawl

Try it

Crawl multiple URLs based on options

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/crawl \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "excludePaths": [\
        "<string>"\
      ],
      "includePaths": [\
        "<string>"\
      ],
      "maxDepth": 10,
      "maxDiscoveryDepth": 123,
      "ignoreSitemap": false,
      "ignoreQueryParameters": false,
      "limit": 10000,
      "allowBackwardLinks": false,
      "crawlEntireDomain": false,
      "allowExternalLinks": false,
      "allowSubdomains": false,
      "delay": 123,
      "maxConcurrency": 123,
      "webhook": {
        "url": "<string>",
        "headers": {},
        "metadata": {},
        "events": [\
          "completed"\
        ]
      },
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": [\
          "markdown"\
        ],
        "changeTrackingOptions": {
          "modes": [\
            "git-diff"\
          ],
          "schema": {},
          "prompt": "<string>",
          "tag": null
        }
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "url": "<string>"
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/crawl-post.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/crawl-post)

[Get Batch Scrape Errors](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape-get-errors)
[Get Crawl Status](https://docs.firecrawl.dev/api-reference/endpoint/crawl-get)

Assistant

Responses are generated using AI and may contain mistakes.

## Credit Usage Endpoint
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Account Endpoints

Credit Usage

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get remaining credits for the authenticated team

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/team/credit-usage \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "remaining_credits": 1000
      }
    }

GET

/

team

/

credit-usage

Try it

Get remaining credits for the authenticated team

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/team/credit-usage \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "remaining_credits": 1000
      }
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Response

200

200404500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/credit-usage.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/credit-usage)

[Get Extract Status](https://docs.firecrawl.dev/api-reference/endpoint/extract-get)
[Token Usage](https://docs.firecrawl.dev/api-reference/endpoint/token-usage)

Assistant

Responses are generated using AI and may contain mistakes.

## Extract Endpoint API
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Extract Endpoints

Extract

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Extract structured data from pages using LLMs

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/extract \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "urls": [\
        "<string>"\
      ],
      "prompt": "<string>",
      "schema": {},
      "enableWebSearch": false,
      "ignoreSitemap": false,
      "includeSubdomains": true,
      "showSources": false,
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": [\
          "markdown"\
        ],
        "changeTrackingOptions": {
          "modes": [\
            "git-diff"\
          ],
          "schema": {},
          "prompt": "<string>",
          "tag": null
        }
      },
      "ignoreInvalidURLs": false
    }'

200

400

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "invalidURLs": [\
        "<string>"\
      ]
    }

POST

/

extract

Try it

Extract structured data from pages using LLMs

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/extract \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "urls": [\
        "<string>"\
      ],
      "prompt": "<string>",
      "schema": {},
      "enableWebSearch": false,
      "ignoreSitemap": false,
      "includeSubdomains": true,
      "showSources": false,
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": [\
          "markdown"\
        ],
        "changeTrackingOptions": {
          "modes": [\
            "git-diff"\
          ],
          "schema": {},
          "prompt": "<string>",
          "tag": null
        }
      },
      "ignoreInvalidURLs": false
    }'

200

400

500

Copy

Ask AI

    {
      "success": true,
      "id": "<string>",
      "invalidURLs": [\
        "<string>"\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/extract#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200400500

application/json

Successful extraction

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/extract.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/extract)

[Search](https://docs.firecrawl.dev/api-reference/endpoint/search)
[Get Extract Status](https://docs.firecrawl.dev/api-reference/endpoint/extract-get)

Assistant

Responses are generated using AI and may contain mistakes.

## Get Extract Status
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Extract Endpoints

Get Extract Status

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get the status of an extract job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/extract/{id} \
      --header 'Authorization: Bearer <token>'

200

Copy

Ask AI

    {
      "success": true,
      "data": {},
      "status": "completed",
      "expiresAt": "2023-11-07T05:31:56Z"
    }

GET

/

extract

/

{id}

Try it

Get the status of an extract job

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/extract/{id} \
      --header 'Authorization: Bearer <token>'

200

Copy

Ask AI

    {
      "success": true,
      "data": {},
      "status": "completed",
      "expiresAt": "2023-11-07T05:31:56Z"
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Path Parameters

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/extract-get#parameter-id)

id

string<uuid>

required

The ID of the extract job

#### Response

200 - application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/extract-get.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/extract-get)

[Extract](https://docs.firecrawl.dev/api-reference/endpoint/extract)
[Credit Usage](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage)

Assistant

Responses are generated using AI and may contain mistakes.

## Map Endpoint API
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Map Endpoints

Map

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Map multiple URLs based on options

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/map \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "search": "<string>",
      "ignoreSitemap": true,
      "sitemapOnly": false,
      "includeSubdomains": true,
      "limit": 5000,
      "timeout": 123
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "links": [\
        "<string>"\
      ]
    }

POST

/

map

Try it

Map multiple URLs based on options

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/map \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "search": "<string>",
      "ignoreSitemap": true,
      "sitemapOnly": false,
      "includeSubdomains": true,
      "limit": 5000,
      "timeout": 123
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "links": [\
        "<string>"\
      ]
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/map#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/map.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/map)

[Get Active Crawls](https://docs.firecrawl.dev/api-reference/endpoint/crawl-active)
[Search](https://docs.firecrawl.dev/api-reference/endpoint/search)

Assistant

Responses are generated using AI and may contain mistakes.

## Scrape Endpoint API
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Scrape Endpoints

Scrape

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Scrape a single URL and optionally extract information using an LLM

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/scrape \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "onlyMainContent": true,
      "includeTags": [\
        "<string>"\
      ],
      "excludeTags": [\
        "<string>"\
      ],
      "maxAge": 0,
      "headers": {},
      "waitFor": 0,
      "mobile": false,
      "skipTlsVerification": false,
      "timeout": 30000,
      "parsePDF": true,
      "jsonOptions": {
        "schema": {},
        "systemPrompt": "<string>",
        "prompt": "<string>"
      },
      "actions": [\
        {\
          "type": "wait",\
          "milliseconds": 2,\
          "selector": "#my-element"\
        }\
      ],
      "location": {
        "country": "US",
        "languages": [\
          "en-US"\
        ]
      },
      "removeBase64Images": true,
      "blockAds": true,
      "proxy": "basic",
      "storeInCache": true,
      "formats": [\
        "markdown"\
      ],
      "changeTrackingOptions": {
        "modes": [\
          "git-diff"\
        ],
        "schema": {},
        "prompt": "<string>",
        "tag": null
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "markdown": "<string>",
        "html": "<string>",
        "rawHtml": "<string>",
        "screenshot": "<string>",
        "links": [\
          "<string>"\
        ],
        "actions": {
          "screenshots": [\
            "<string>"\
          ],
          "scrapes": [\
            {\
              "url": "<string>",\
              "html": "<string>"\
            }\
          ],
          "javascriptReturns": [\
            {\
              "type": "<string>",\
              "value": "<any>"\
            }\
          ],
          "pdfs": [\
            "<string>"\
          ]
        },
        "metadata": {
          "title": "<string>",
          "description": "<string>",
          "language": "<string>",
          "sourceURL": "<string>",
          "<any other metadata> ": "<string>",
          "statusCode": 123,
          "error": "<string>"
        },
        "llm_extraction": {},
        "warning": "<string>",
        "changeTracking": {
          "previousScrapeAt": "2023-11-07T05:31:56Z",
          "changeStatus": "new",
          "visibility": "visible",
          "diff": "<string>",
          "json": {}
        }
      }
    }

POST

/

scrape

Try it

Scrape a single URL and optionally extract information using an LLM

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/scrape \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "url": "<string>",
      "onlyMainContent": true,
      "includeTags": [\
        "<string>"\
      ],
      "excludeTags": [\
        "<string>"\
      ],
      "maxAge": 0,
      "headers": {},
      "waitFor": 0,
      "mobile": false,
      "skipTlsVerification": false,
      "timeout": 30000,
      "parsePDF": true,
      "jsonOptions": {
        "schema": {},
        "systemPrompt": "<string>",
        "prompt": "<string>"
      },
      "actions": [\
        {\
          "type": "wait",\
          "milliseconds": 2,\
          "selector": "#my-element"\
        }\
      ],
      "location": {
        "country": "US",
        "languages": [\
          "en-US"\
        ]
      },
      "removeBase64Images": true,
      "blockAds": true,
      "proxy": "basic",
      "storeInCache": true,
      "formats": [\
        "markdown"\
      ],
      "changeTrackingOptions": {
        "modes": [\
          "git-diff"\
        ],
        "schema": {},
        "prompt": "<string>",
        "tag": null
      },
      "zeroDataRetention": false
    }'

200

402

429

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "markdown": "<string>",
        "html": "<string>",
        "rawHtml": "<string>",
        "screenshot": "<string>",
        "links": [\
          "<string>"\
        ],
        "actions": {
          "screenshots": [\
            "<string>"\
          ],
          "scrapes": [\
            {\
              "url": "<string>",\
              "html": "<string>"\
            }\
          ],
          "javascriptReturns": [\
            {\
              "type": "<string>",\
              "value": "<any>"\
            }\
          ],
          "pdfs": [\
            "<string>"\
          ]
        },
        "metadata": {
          "title": "<string>",
          "description": "<string>",
          "language": "<string>",
          "sourceURL": "<string>",
          "<any other metadata> ": "<string>",
          "statusCode": 123,
          "error": "<string>"
        },
        "llm_extraction": {},
        "warning": "<string>",
        "changeTracking": {
          "previousScrapeAt": "2023-11-07T05:31:56Z",
          "changeStatus": "new",
          "visibility": "visible",
          "diff": "<string>",
          "json": {}
        }
      }
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/scrape#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200402429500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/scrape.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/scrape)

[Introduction](https://docs.firecrawl.dev/api-reference/introduction)
[Batch Scrape](https://docs.firecrawl.dev/api-reference/endpoint/batch-scrape)

Assistant

Responses are generated using AI and may contain mistakes.

## Search API Endpoint
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Search Endpoints

Search

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Search and optionally scrape search results

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/search \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "query": "<string>",
      "limit": 5,
      "tbs": "<string>",
      "location": "<string>",
      "timeout": 60000,
      "ignoreInvalidURLs": false,
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": []
      }
    }'

200

408

500

Copy

Ask AI

    {
      "success": true,
      "data": [\
        {\
          "title": "<string>",\
          "description": "<string>",\
          "url": "<string>",\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "sourceURL": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ],
      "warning": "<string>"
    }

POST

/

search

Try it

Search and optionally scrape search results

cURL

Copy

Ask AI

    curl --request POST \
      --url https://api.firecrawl.dev/v1/search \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "query": "<string>",
      "limit": 5,
      "tbs": "<string>",
      "location": "<string>",
      "timeout": 60000,
      "ignoreInvalidURLs": false,
      "scrapeOptions": {
        "onlyMainContent": true,
        "includeTags": [\
          "<string>"\
        ],
        "excludeTags": [\
          "<string>"\
        ],
        "maxAge": 0,
        "headers": {},
        "waitFor": 0,
        "mobile": false,
        "skipTlsVerification": false,
        "timeout": 30000,
        "parsePDF": true,
        "jsonOptions": {
          "schema": {},
          "systemPrompt": "<string>",
          "prompt": "<string>"
        },
        "actions": [\
          {\
            "type": "wait",\
            "milliseconds": 2,\
            "selector": "#my-element"\
          }\
        ],
        "location": {
          "country": "US",
          "languages": [\
            "en-US"\
          ]
        },
        "removeBase64Images": true,
        "blockAds": true,
        "proxy": "basic",
        "storeInCache": true,
        "formats": []
      }
    }'

200

408

500

Copy

Ask AI

    {
      "success": true,
      "data": [\
        {\
          "title": "<string>",\
          "description": "<string>",\
          "url": "<string>",\
          "markdown": "<string>",\
          "html": "<string>",\
          "rawHtml": "<string>",\
          "links": [\
            "<string>"\
          ],\
          "screenshot": "<string>",\
          "metadata": {\
            "title": "<string>",\
            "description": "<string>",\
            "sourceURL": "<string>",\
            "statusCode": 123,\
            "error": "<string>"\
          }\
        }\
      ],
      "warning": "<string>"
    }

The search endpoint combines web search (SERP) with Firecrawl‚Äôs scraping capabilities to return full page content for any query. Include `scrapeOptions` with `formats: ["markdown"]` to get complete markdown content for each search result otherwise you will default to getting the SERP results (url, title, description).

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/search#supported-query-operators)

Supported query operators
--------------------------------------------------------------------------------------------------------------------

We support a variety of query operators that allow you to filter your searches better.

| Operator | Functionality | Examples |
| --- | --- | --- |
| `""` | Non-fuzzy matches a string of text | `"Firecrawl"` |
| `-` | Excludes certain keywords or negates other operators | `-bad`, `-site:firecrawl.dev` |
| `site:` | Only returns results from a specified website | `site:firecrawl.dev` |
| `inurl:` | Only returns results that include a word in the URL | `inurl:firecrawl` |
| `allinurl:` | Only returns results that include multiple words in the URL | `allinurl:git firecrawl` |
| `intitle:` | Only returns results that include a word in the title of the page | `intitle:Firecrawl` |
| `allintitle:` | Only returns results that include multiple words in the title of the page | `allintitle:firecrawl playground` |
| `related:` | Only returns results that are related to a specific domain | `related:firecrawl.dev` |

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/search#location-parameter)

Location Parameter
------------------------------------------------------------------------------------------------------

Use the `location` parameter to get geo-targeted search results. Format: `"string"`. Examples: `"Germany"`, `"San Francisco,California,United States"`. See the [complete list of supported locations](https://firecrawl.dev/search_locations.json)
 for all available countries and languages.

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/search#time-based-search)

Time-Based Search
----------------------------------------------------------------------------------------------------

Use the `tbs` parameter to filter results by time periods, including custom date ranges. See the [Search Feature documentation](https://docs.firecrawl.dev/features/search#time-based-search)
 for detailed examples and supported formats.

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/search#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Body

application/json

#### Response

200

200408500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/search.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/search)

[Map](https://docs.firecrawl.dev/api-reference/endpoint/map)
[Extract](https://docs.firecrawl.dev/api-reference/endpoint/extract)

Assistant

Responses are generated using AI and may contain mistakes.

## Token Usage Endpoint
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Account Endpoints

Token Usage

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

Get remaining tokens for the authenticated team (Extract only)

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/team/token-usage \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "remaining_tokens": 1000
      }
    }

GET

/

team

/

token-usage

Try it

Get remaining tokens for the authenticated team (Extract only)

cURL

Copy

Ask AI

    curl --request GET \
      --url https://api.firecrawl.dev/v1/team/token-usage \
      --header 'Authorization: Bearer <token>'

200

404

500

Copy

Ask AI

    {
      "success": true,
      "data": {
        "remaining_tokens": 1000
      }
    }

#### Authorizations

[‚Äã](https://docs.firecrawl.dev/api-reference/endpoint/token-usage#authorization-authorization)

Authorization

string

header

required

Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.

#### Response

200

200404500

application/json

Successful response

The response is of type `object`.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/endpoint/token-usage.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/endpoint/token-usage)

[Credit Usage](https://docs.firecrawl.dev/api-reference/endpoint/credit-usage)

Assistant

Responses are generated using AI and may contain mistakes.

## Firecrawl API Overview
[Firecrawl Docs home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo.png)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/firecrawl/logo/logo-dark.png)](https://firecrawl.dev/)

v1

Search...

‚åòKAsk AI

Search...

Navigation

Using the API

Introduction

[Documentation](https://docs.firecrawl.dev/introduction)
[SDKs](https://docs.firecrawl.dev/sdks/overview)
[Learn](https://www.firecrawl.dev/blog/category/tutorials)
[Integrations](https://www.firecrawl.dev/app)
[API Reference](https://docs.firecrawl.dev/api-reference/introduction)

On this page

*   [Features](https://docs.firecrawl.dev/api-reference/introduction#features)
    
*   [Agentic Features](https://docs.firecrawl.dev/api-reference/introduction#agentic-features)
    
*   [Base URL](https://docs.firecrawl.dev/api-reference/introduction#base-url)
    
*   [Authentication](https://docs.firecrawl.dev/api-reference/introduction#authentication)
    
*   [Response codes](https://docs.firecrawl.dev/api-reference/introduction#response-codes)
    
*   [Rate limit](https://docs.firecrawl.dev/api-reference/introduction#rate-limit)
    

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#features)

Features
-------------------------------------------------------------------------------

[Scrape\
------\
\
Extract content from any webpage in markdown or json format.](https://docs.firecrawl.dev/api-reference/endpoint/scrape)
[Crawl\
-----\
\
Crawl entire websites, extract their content and metadata.](https://docs.firecrawl.dev/api-reference/endpoint/crawl-post)
[Map\
---\
\
Get a complete list of URLs from any website quickly and reliably.](https://docs.firecrawl.dev/api-reference/endpoint/map)
[Search\
------\
\
Search the web and get full page content in any format.](https://docs.firecrawl.dev/api-reference/endpoint/search)

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#agentic-features)

Agentic Features
-----------------------------------------------------------------------------------------------

[Extract\
-------\
\
Extract structured data from entire webpages using natural language.](https://docs.firecrawl.dev/api-reference/endpoint/extract)

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#base-url)

Base URL
-------------------------------------------------------------------------------

All requests contain the following base URL:

Copy

Ask AI

    https://api.firecrawl.dev 
    

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#authentication)

Authentication
-------------------------------------------------------------------------------------------

For authentication, it‚Äôs required to include an Authorization header. The header should contain `Bearer fc-123456789`, where `fc-123456789` represents your API Key.

Copy

Ask AI

    Authorization: Bearer fc-123456789
    

‚Äã

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#response-codes)

Response codes
-------------------------------------------------------------------------------------------

Firecrawl employs conventional HTTP status codes to signify the outcome of your requests. Typically, 2xx HTTP status codes denote success, 4xx codes represent failures related to the user, and 5xx codes signal infrastructure problems.

| Status | Description |
| --- | --- |
| 200 | Request was successful. |
| 400 | Verify the correctness of the parameters. |
| 401 | The API key was not provided. |
| 402 | Payment required |
| 404 | The requested resource could not be located. |
| 429 | The rate limit has been surpassed. |
| 5xx | Signifies a server error with Firecrawl. |

Refer to the Error Codes section for a detailed explanation of all potential API errors. ‚Äã

[‚Äã](https://docs.firecrawl.dev/api-reference/introduction#rate-limit)

Rate limit
-----------------------------------------------------------------------------------

The Firecrawl API has a rate limit to ensure the stability and reliability of the service. The rate limit is applied to all endpoints and is based on the number of requests made within a specific time frame. When you exceed the rate limit, you will receive a 429 response code.

[Suggest edits](https://github.com/mendableai/firecrawl-docs/edit/main/api-reference/introduction.mdx)
[Raise issue](https://github.com/mendableai/firecrawl-docs/issues/new?title=Issue%20on%20docs&body=Path:%20/api-reference/introduction)

[Scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)

Assistant

Responses are generated using AI and may contain mistakes.

